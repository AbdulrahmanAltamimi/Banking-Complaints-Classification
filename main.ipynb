{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d50362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ddb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"complaints_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cf25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f2163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word = word2Vec.get_mean_vector([\"hello\" ,\"all\" ,\"the word\"],pre_normalize=True) \n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f10fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['narrative'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dda9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['narrative'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3227e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['narrative'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5394e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the nan rows\n",
    "df= df.dropna(subset=['narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd85082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['narrative'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e86b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate rows \n",
    "df = df.drop_duplicates() \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e43c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.iloc[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adee06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['narrative'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['narrative'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c824b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_vectorize(text):\n",
    "    words = tokenizer.tokenize(text)\n",
    "    words_lower = [word.lower() for word in words]\n",
    "    tokens=[]\n",
    "    for token in words_lower:\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "        if token in word2Vec.key_to_index: \n",
    "            tokens.append(token)\n",
    "    if tokens:\n",
    "        return word2Vec.get_mean_vector(tokens)\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eedcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new['vector'] = df_new['narrative'].apply(lambda narrative: preprocess_vectorize(narrative))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074925e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['product_num'] = df_new['product'].map({\n",
    "    'credit_card': 0 , \n",
    "    'retail_banking': 1 , \n",
    "    'credit_reporting': 2 , \n",
    "    'mortgages_and_loans': 3 , \n",
    "    'debt_collection': 4 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ae65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new[\"vector\"][4000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_new['vector']\n",
    "y = df_new['product_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack(x)\n",
    "y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "x_smote, y_smote = SMOTE().fit_resample(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07713b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_smote, \n",
    "    y_smote, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=42,\n",
    "    stratify = y_smote\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74855243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier , VotingClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    Z,\n",
    "    \"voiting\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(),\n",
    "    VotingClassifier(estimators=[\n",
    "        ('rbfsvm',SVC(probability=True)),\n",
    "        ('rf',RandomForestClassifier()),\n",
    "        ('nu', MLPClassifier())\n",
    "        ],\n",
    "        voting='soft')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        pred = clf.predict(X_test)\n",
    "        f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "        print(f'classifier: {name} | the score is: {score} | the f1 is: {f1} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
